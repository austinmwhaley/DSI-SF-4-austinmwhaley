{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 10px;\">\n",
    "\n",
    "# 1.3 - Intro to Web Scraping\n",
    "\n",
    "---\n",
    "\n",
    "Week 4 - 1.3\n",
    "\n",
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- Understand scraping basics\n",
    "- Familiarity with import.io service\n",
    "- XPath basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Control + Option + U = access backend code\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STUDENT PRE-WORK\n",
    "*Before this lesson, you should already be able to:*\n",
    "- Understand basic HTML concepts\n",
    "- Worked with Beautiful Soup\n",
    "- Signed up for import.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LESSON GUIDE\n",
    "| TIMING  | TYPE  | TOPIC  |\n",
    "|:-:|---|---|\n",
    "| 5 min  | [Opening](#opening)  | Overview of what scraping is/does |\n",
    "| 10 min  | [Introduction](#introduction)   | Explain what scraping is |\n",
    "| 15 min  | [Demo](#demo)  | Python Library BeautifulSoup |\n",
    "| 25 min  | [Guided Practice](#guided-practice)  | Import.io |\n",
    "| 25 min  | [Independent Practice](#ind-practice)  | Import.io  |\n",
    "| 5 min  | [Conclusion](#conclusion)  |  How it works with Import.IO |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Scraping Overview (10 mins)\n",
    "\n",
    "Web scraping is a technique of extracting information from websites. It focuses on transformation of unstructured data on the web, into structured data that can be stored and analyzed.\n",
    "\n",
    "There are a variety of ways to \"scrape\" what we want from the web:\n",
    "\n",
    "- 3rd Party Services (import.io)\n",
    "- Write our own Python apps that pull HTML documents and parse them\n",
    "  - Mechanize\n",
    "  - Scrapy\n",
    "  - Requests\n",
    "  - libxml / XPath\n",
    "  - Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3 mins) What is hardest to understand about scraping?\n",
    "_ie: If you were asked to scrape craigslist property listings and put them in a DataFrame(), what would hold you up?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Review\n",
    "\n",
    "In the HTML DOM (Document Object Model), everything is a node:\n",
    " * The document itself is a document node.\n",
    " * All HTML elements are element nodes.\n",
    " * All HTML attributes are attribute nodes.\n",
    " * Text inside HTML elements are text nodes.\n",
    " * Comments are comment nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am a title\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements\n",
    "Elements begin and end with **open and close \"tags\"**, which are defined by namespaced, encapsulated strings. \n",
    "\n",
    "```html\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "_note: the tags **title, p, and strong** are represented here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element Parent / Child Relationships\n",
    "\n",
    "<img src=\"http://www.htmlgoodies.com/img/2007/06/flowChart2.gif\" width=\"250\">\n",
    "\n",
    "**Elements begin and end in the same namespace like so:**  `<p></p>`\n",
    "\n",
    "**Elements can have parents and children:**\n",
    "\n",
    "```html\n",
    "<body>\n",
    "    <div>I am inside the parent element\n",
    "        <div>I am inside a child element</div>\n",
    "        <div>I am inside another child element</div>\n",
    "        <div>I am inside yet another child element</div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element Attributes\n",
    "\n",
    "Elements can also have attributes!  Attributes are defined inside **element tags** and can contain data that may be useful to scrape.\n",
    "\n",
    "```html\n",
    "<a href=\"http://lmgtfy.com/?q=html+element+attributes\" title=\"A title\" id=\"web-link\" name=\"hal\">A Simple Link</a>\n",
    "```\n",
    "\n",
    "The **element attributes** of this `<a>` tag element are:\n",
    "- id\n",
    "- href\n",
    "- title\n",
    "- name\n",
    "\n",
    "This `<a>` tag example will render in your browser like this:\n",
    "> <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">A Simple Link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3 mins) Can you identify an attribute, an element, a text item, and a child element?\n",
    "\n",
    "```HTML\n",
    "<html>\n",
    "   <title id=\"main-title\">All this scraping is making me itch!</title>\n",
    "   <body>\n",
    "       <h1>Welcome to my Homepage</h1>\n",
    "       <p id=\"welcome-paragraph\" class=\"strong-paragraph\">\n",
    "           <span>Hello friends, let me tell you about this cool hair product..</span>\n",
    "           <ul>\n",
    "              <li>It's cool</li>\n",
    "              <li>It's fresh</li>\n",
    "              <li>It can tell the future</li>\n",
    "              <li>Always be closing</li>\n",
    "           </ul>\n",
    "       </p>\n",
    "   </body>\n",
    "```\n",
    "\n",
    "**Bonus: What's missing?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter XPath\n",
    "\n",
    "XPath uses path expressions to select nodes or node-sets in an HTML/XML document. These path expressions look very much like the expressions you see when you work with a traditional computer file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPath Features\n",
    "\n",
    "XPath includes over 100 built-in functions to help us select and manipulate HTML (or XML) documents. XPath has functions for:\n",
    "\n",
    "- string values\n",
    "- numeric values\n",
    "- date and time comparison\n",
    "- sequence manipulation\n",
    "- Boolean values\n",
    "- and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic XPath Expressions\n",
    "\n",
    "XPath comes with a wide array of features but the basics of selecting data are the most common problems that XPath can help you solve.\n",
    "\n",
    "The most common task you'll use **XPath** for is selecting data from HTML documents.  There are two ways you can **select elements** within HTML using **XPath**:\n",
    "\n",
    "- Absolute reference\n",
    "- Relative reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XPath:  Absolute References\n",
    "\n",
    "_For our XPath demonstration, we will use Scrapy, which is using libxml under the hood.  Libxml provides the basic functionality for XPath expressions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install scrapy\n",
    "# pip install --upgrade zope2\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <span id=\"only-span\">good</span>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# The same thing but \"absolute\" reference\n",
    "Selector(text=HTML).xpath('/html/body/span/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Reference\n",
    "\n",
    "Relative references in XPath match the \"ends\" of structures.  Since there is only a single \"span\" element, `//span/text()` matches **one element**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Attributes\n",
    "\n",
    "Attributes **within a tag**, such as `id=\"only-span\"` within our span attribute.  We can get the attribute by using `@` symbol **after** the **element reference**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'only-span']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/@id').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (~10 mins) Where's Waldo - \"XPath Edition\"\n",
    "\n",
    "In this example, we will find Waldo together.  Find Waldo as:\n",
    "\n",
    "- Element\n",
    "- Attribute\n",
    "- Text element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'nerds',\n",
       " u'alpha',\n",
       " u'alpha',\n",
       " u'beta',\n",
       " u'animal',\n",
       " u'tdawg',\n",
       " u'dsi-rocks']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//@class').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        \n",
    "        <ul id=\"waldo\">\n",
    "            <li class=\"waldo\">\n",
    "                <span> yo Im not here</span>\n",
    "            </li>\n",
    "            <li class=\"waldo\">Height:  ???</li>\n",
    "            <li class=\"waldo\">Weight:  ???</li>\n",
    "            <li class=\"waldo\">Last Location:  ???</li>\n",
    "            <li class=\"nerds\">\n",
    "                <div class=\"alpha\">Bill gates</div>\n",
    "                <div class=\"alpha\">Zuckerberg</div>\n",
    "                <div class=\"beta\">Theil</div>\n",
    "                <div class=\"animal\">parker</div>\n",
    "            </li>\n",
    "        </ul>\n",
    "        \n",
    "        <ul id=\"tim\">\n",
    "            <li class=\"tdawg\">\n",
    "                <span>yo im here</span>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <li>stuff</li>\n",
    "        <li>stuff2</li>\n",
    "        \n",
    "        <div id=\"cooldiv\">\n",
    "            <span class=\"dsi-rocks\">\n",
    "               YO!\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <waldo>Waldo</waldo>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' yo Im not here']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "Selector(text=HTML).xpath(\"/html/body/ul[@id = 'waldo']/li/span/text()\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'yo im here']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extact 'yo im here'\n",
    "Selector(text=HTML).xpath(\"/html/body/ul/li[@class='tdawg']/span/text()\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<div class=\"alpha\">Bill gates</div>',\n",
       " u'<div class=\"alpha\">Zuckerberg</div>',\n",
       " u'<div class=\"beta\">Theil</div>',\n",
       " u'<div class=\"animal\">parker</div>',\n",
       " u'<div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract all child classes div\n",
    "Selector(text=HTML).xpath(\"//div\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='/html/body/ul[@id=\"tim\"]' data=u'<ul id=\"tim\">\\n            <li class=\"tda'>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('/html/body/ul[@id=\"tim\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'waldo']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find absolute element\n",
    "#Selector(text=HTML).xpath('/html/body/waldo/text()').extract()\n",
    "# Selector(text=HTML).xpath('/html/body/ul/li/text()').extract()\n",
    "\n",
    "# Find relative element\n",
    "# Selector(text=HTML).xpath('//li').extract()\n",
    "\n",
    "# Find element attribute\n",
    "# Selector(text=HTML).xpath('////@class').extract()\n",
    "# Selector(text=HTML).xpath('//ul/@id').extract()\n",
    "\n",
    "\n",
    "# Find element text\n",
    "# Selector(text=HTML).xpath('').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 vs N Selections\n",
    "\n",
    "When selecting elements via relative reference, it's possible that you will select multiple items.  It's still possible to select single items, if you're specfic enough.\n",
    "\n",
    "**Singular Reference**\n",
    "- **Index** starts at **1**\n",
    "- Selections by offset\n",
    "- Selections by \"first\" or \"last\"\n",
    "- Selections by **unique attribute value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "    \n",
    "        <!-- Search Results -->\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=751hUX_q0Do\" title=\"Rappin with Gas\">Rapping with gas</a>\n",
    "           <span class=\"link-details\">This is a great video about gas.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=97byWqi-zsI\" title=\"Casio Rapmap\">The Rapmaster</a>\n",
    "           <span class=\"link-details\">My first synth ever.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=TSwqnR327fk\" title=\"Cinco Products\">Cinco Midi Organizer</a>\n",
    "           <span class=\"link-details\">Midi files at the speed of light.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">BBG Baddest Moments</a>\n",
    "           <span class=\"link-details\">It's tough to be a gangster.</span>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Page stats -->\n",
    "        <div class=\"page-stats-container\">\n",
    "            <li class=\"item\" id=\"pageviews\">1,333,443</li>\n",
    "            <li class=\"item\" id=\"somethingelse\">bla</li>\n",
    "            <li class=\"item\" id=\"last-viewed\">01-22-2016</li>\n",
    "            <li class=\"item\" id=\"views-per-hour\">1,532</li>\n",
    "            <li class=\"item\" id=\"kiefer-views-per-hour\">5,233.42</li>\n",
    "        </div>\n",
    "        \n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Rapping with gas']\n",
      "[u'The Rapmaster']\n",
      "[u'Cinco Midi Organizer']\n",
      "[u'BBG Baddest Moments']\n"
     ]
    }
   ],
   "source": [
    "for row in Selector(text=HTML).xpath('/html/body/div[@class=\"search-result\"]'):\n",
    "    print row.xpath('./a/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<div class=\"search-result\">\\n           <a href=\"https://www.youtube.com/watch?v=751hUX_q0Do\" title=\"Rappin with Gas\">Rapping with gas</a>\\n           <span class=\"link-details\">This is a great video about gas.</span>\\n        </div>',\n",
       " u'<div class=\"search-result\">\\n           <a href=\"https://www.youtube.com/watch?v=97byWqi-zsI\" title=\"Casio Rapmap\">The Rapmaster</a>\\n           <span class=\"link-details\">My first synth ever.</span>\\n        </div>',\n",
       " u'<div class=\"search-result\">\\n           <a href=\"https://www.youtube.com/watch?v=TSwqnR327fk\" title=\"Cinco Products\">Cinco Midi Organizer</a>\\n           <span class=\"link-details\">Midi files at the speed of light.</span>\\n        </div>',\n",
       " u'<div class=\"search-result\">\\n           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">BBG Baddest Moments</a>\\n           <span class=\"link-details\">It\\'s tough to be a gangster.</span>\\n        </div>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = Selector(text=HTML).xpath('/html/body/div[@class=\"search-result\"]').extract()\n",
    "span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the first element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">Midi files at the speed of light.</span>'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the last element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting all elements matching a selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<span class=\"link-details\">This is a great video about gas.</span>',\n",
       " u'<span class=\"link-details\">My first synth ever.</span>',\n",
       " u'<span class=\"link-details\">Midi files at the speed of light.</span>',\n",
       " u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting elements matching an _attribute_\n",
    "\n",
    "This will be one of the most common ways you will select items.  HTML DOM elements will be more differentiated based on their \"class\" and \"id\" variables.  Mainly, these types of attributes are used by web developers to refer to specfic elements or a broad set of elements to apply visual characteristics using CSS.\n",
    "\n",
    "```HTML \n",
    "//element[@attribute=\"value\"]\n",
    "```\n",
    "\n",
    "**Generally**\n",
    "\n",
    "- \"class\" attributes within elements usually refer to multiple items\n",
    "- \"id\" attributes are supposed to be unique, but not always\n",
    "\n",
    "_CSS stands for cascading style sheets.  These are used to abstract the definition of visual elements on a micro and macro scale for the web.  They are also our best friend as data miners.  They give us strong hints and cues as to how a web document is structured._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<li class=\"item\" id=\"pageviews\">1,333,443</li>']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_details</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a great video about gas.</td>\n",
       "      <td>Rapping with gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My first synth ever.</td>\n",
       "      <td>The Rapmaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Too hot for kiefer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midi files at the speed of light.</td>\n",
       "      <td>Cinco Midi Organizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>DSI true data stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It's tough to be a gangster.</td>\n",
       "      <td>BBG Baddest Moments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        link_details                  title\n",
       "0   This is a great video about gas.       Rapping with gas\n",
       "1               My first synth ever.          The Rapmaster\n",
       "2                                        Too hot for kiefer\n",
       "3  Midi files at the speed of light.   Cinco Midi Organizer\n",
       "4                                     DSI true data stories\n",
       "5       It's tough to be a gangster.    BBG Baddest Moments"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "    \n",
    "        <!-- Search Results -->\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=751hUX_q0Do\" title=\"Rappin with Gas\">Rapping with gas</a>\n",
    "           <span class=\"link-details\">This is a great video about gas.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=97byWqi-zsI\" title=\"Casio Rapmap\">The Rapmaster</a>\n",
    "           <span class=\"link-details\">My first synth ever.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">Too hot for kiefer</a>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=TSwqnR327fk\" title=\"Cinco Products\">Cinco Midi Organizer</a>\n",
    "           <span class=\"link-details\">Midi files at the speed of light.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">DSI true data stories</a>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">BBG Baddest Moments</a>\n",
    "           <span class=\"link-details\">It's tough to be a gangster.</span>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Page stats -->\n",
    "        <div class=\"page-stats-container\">\n",
    "            <li class=\"item\" id=\"pageviews\">1,333,443</li>\n",
    "            <li class=\"item\" id=\"somethingelse\">bla</li>\n",
    "            <li class=\"item\" id=\"last-viewed\">01-22-2016</li>\n",
    "            <li class=\"item\" id=\"views-per-hour\">1,532</li>\n",
    "            <li class=\"item\" id=\"kiefer-views-per-hour\">5,233.42</li>\n",
    "        </div>\n",
    "        \n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for row in Selector(text=HTML).xpath('/html/body/div[@class=\"search-result\"]'):\n",
    "    \n",
    "    link_details = row.xpath(\"./span/text()\").extract()\n",
    "    \n",
    "    if len(link_details) == 0:\n",
    "        link_details = \"\"\n",
    "    else :\n",
    "        link_details = link_details[0]\n",
    "    \n",
    "    search_results.append({\n",
    "        'title': row.xpath(\"./a/text()\").extract()[0],\n",
    "        'link_details': link_details\n",
    "    })\n",
    "    \n",
    "pd.DataFrame(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Code:\n",
    "\n",
    " - How can we get a series of only text items for the page statistics section of our page?\n",
    " - We want to know only how many times Kiefer views my Youtube videos page per hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<li class=\"item\" id=\"pageviews\">1,333,443</li>',\n",
       " u'<li class=\"item\" id=\"last-viewed\">01-22-2016</li>',\n",
       " u'<li class=\"item\" id=\"views-per-hour\">1,532</li>',\n",
       " u'<li class=\"item\" id=\"kiefer-views-per-hour\">5,233.42</li>',\n",
       " u'<li class=\"item2\" id=\"pageviews\">1,333,443 - 2</li>',\n",
       " u'<li class=\"item2\" id=\"last-viewed\">01-22-2016 - 2</li>',\n",
       " u'<li class=\"item2\" id=\"views-per-hour\">1,532 - 2</li>',\n",
       " u'<li class=\"item2\" id=\"kiefer-views-per-hour\">5,233.42 - 2</li>']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all text elements for the page statistics section\n",
    "Selector(text=HTML).xpath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "# Selector(text=HTML).xpath('//div[@class=\"page-stats-container\"]/li[4]/text()').extract()\n",
    "\n",
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "Selector(text=HTML).xpath('//li[@id=\"kiefer-views-per-hour\"]/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Note:  Requests\n",
    "\n",
    "The requests module is the gateway to interacting with the web using Python.  We can:\n",
    "\n",
    " - Fetch web documents as strings\n",
    " - Decode JSON\n",
    " - Basic data munging with Web Documents\n",
    " - Download static files that are not text\n",
    "  - Images\n",
    "  - Videos\n",
    "  - Binary data\n",
    "\n",
    "\n",
    "Take some time and read up on Requests:\n",
    "\n",
    "http://docs.python-requests.org/en/master/user/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Scrape Data Tau Headlines\n",
    "\n",
    "DataTau is a great site for data science news. Let's take their headlines using Python **requests**, and practice selecting various elements.\n",
    "\n",
    "Using <a href=\"https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en\">XPath helper Chrome plugin</a> _(cmd-shift-x)_ and the Chrome \"inspect\" feature, let's explore the structure of the page.\n",
    "\n",
    "_Here's a <a href=\"https://www.youtube.com/watch?v=i2Li1vnv09U\">concise video</a> that demonstrates the basic inspect feature within Chrome._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<html><head><link rel=\"stylesheet\" type=\"text/css\" href=\"news.css\">\\n<link rel=\"shortcut icon\" href=\"http://www.iconj.com/ico/d/x/dxo02ap56v.ico\">\\n<scr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please only run this frame once to avoid hitting the site too hard all at once\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://www.datatau.com\")\n",
    "HTML = response.text  \n",
    "HTML[0:150]           # view the first 500 characters of the HTML index document for DataTau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Only The Headlines\n",
    "\n",
    "We will use the XPath helper tool to inspect the markup that comprises the **title** to find any pattern.  Since there are more than one **titles**, we expect to find a series of elements representing the **title** data that we are interested in.\n",
    "\n",
    "![](https://snag.gy/m4K3UE.jpg)\n",
    "\n",
    "In this example, we are referencing the the **1st center**, **3rd table row (`tr[3]`)**, within the 2nd **td having a class of \"title\" (`td[@class=\"title\"][2]`)**, and the anchor tag within a **(`a/text()`)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'What We Learned Analyzing Hundreds of Data Science Interviews',\n",
       " u'Forget Python vs. R: how they can work together',\n",
       " u'A Product similarity space with doc2vec',\n",
       " u'70+ Resources for Transitioning to a Data Science Career',\n",
       " u'Occam razor vs. machine learning',\n",
       " u'Category Encoders: sklearn-compatible transformers for non-numeric data',\n",
       " u'Benchmarking 8 of the new Pascal Titan Xs by querying 1.1 Billion Taxi Trips.',\n",
       " u'Inside Airbnb: Bulk collect data from Airbnb',\n",
       " u'Interactive Data Viz of Geospatial Data using DC.js Leaflet.js and Python',\n",
       " u'Computational and Inferential Thinking']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/text()').extract()\n",
    "titles[0:10] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we get the urls from the titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=eTv1dh4a88',\n",
       " u'http://www.octoparse.com/tutorial/extract-information-from-linkedin-public-data-2/',\n",
       " u'http://analyticsplaybook.org/dataviz/api/apple_health_export_analyze_visualize_R.html',\n",
       " u'https://yanirseroussi.com/2016/08/04/is-data-scientist-a-useless-job-title/',\n",
       " u'https://www.citusdata.com/blog/2016/08/12/state-machines-to-run-databases/',\n",
       " u'https://danidelvalle.me/2016/08/08/smartphone-brand-loyalty-and-handset-renewal-analysis/',\n",
       " u'https://medium.com/@akelleh/causal-data-science-721ed63a4027#.b9dczx7uo',\n",
       " u'http://taoofmac.com/space/blog/2016/08/10/0830',\n",
       " u'https://hackerlists.com/tensorflow-resources/',\n",
       " u'http://katbailey.github.io/post/gaussian-processes-for-dummies/',\n",
       " u'https://www.springboard.com/resources/data-scientist-interview-guide',\n",
       " u'http://blog.yhat.com/posts/rodeo-for-windows.html',\n",
       " u'https://github.com/nicholaslocascio/deep-regex',\n",
       " u'https://ttvand.github.io/Winning-approach-of-the-Facebook-V-Kaggle-competition/',\n",
       " u'https://medium.com/data-engineering/modeling-madly-8b2c72eb52be#.6alvc64m6',\n",
       " u'http://www.jeannicholashould.com/getting-your-first-job-in-data-science.html',\n",
       " u'http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html',\n",
       " u'https://blog.dominodatalab.com/joel-test-data-science/',\n",
       " u'https://www.citusdata.com/blog/2016/08/10/sharding-for-a-multi-tenant-app-with-postgres/',\n",
       " u'http://livebook.datascienceheroes.com/',\n",
       " u'http://blog.udacity.com/2015/04/data-science-interview-questions.html',\n",
       " u'http://www.inferentialthinking.com/',\n",
       " u'http://adilmoujahid.com/posts/2016/08/interactive-data-visualization-geospatial-d3-dc-leaflet-python/',\n",
       " u'http://www.octoparse.com/tutorial/how-to-extract-data-from-airbnb/',\n",
       " u'http://tech.marksblogg.com/billion-nyc-taxi-rides-nvidia-pascal-titan-x-mapd.html',\n",
       " u'https://github.com/wdm0006/categorical_encoding',\n",
       " u'http://arogozhnikov.github.io/2016/07/12/secret-of-ml.html',\n",
       " u'https://blog.modeanalytics.com/data-science-career/',\n",
       " u'http://www.bookspace.co/search/?query_book=The+Communist+Manifesto+%28Penguin+Classics%29&plus=liberty&minus=communism',\n",
       " u'https://civisanalytics.com/blog/data-science/2016/08/15/python-r/',\n",
       " u'https://www.springboard.com/blog/data-science-interviews-lessons/']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/@href').extract()\n",
    "urls[::-1]\n",
    "#<a href=\"http://tech.marksblogg.com/faster-queries-google-cloud-dataproc.html\">33x Faster Queries on Google Cloud's Dataproc using Facebook's Presto</a>\n",
    "# titles[0:5] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How can we get the site domain, after the title within the parentheses (ie: stitchfix.com)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domains = Selector(text=HTML).xpath(\"//span[@class='comhead']/text()\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' (springboard.com) ',\n",
       " u' (civisanalytics.com) ',\n",
       " u' (bookspace.co) ',\n",
       " u' (modeanalytics.com) ',\n",
       " u' (github.io) ']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How about the points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'8 points', u'2 points', u'2 points', u'17 points', u'7 points']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = Selector(text=HTML).xpath('//td[@class=\"subtext\"]/span/text()').extract()\n",
    "points[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How about the \"more Link?\"\n",
    "Hint:  You can use `element[text()='exact text']` to find text element matching specific text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=vn4mk4K16d']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_link = Selector(text=HTML).xpath('//a[text()=\"More\"]/@href').extract()\n",
    "next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Practice / Lab\n",
    "\n",
    "For the next 30 minutes try to grab the following:\n",
    "\n",
    "- Story titles\n",
    "- Story URL (href)\n",
    "- Domain\n",
    "- Points\n",
    "\n",
    "Stretch:\n",
    "- Author\n",
    "- Comment count\n",
    "\n",
    "Then put into a DataFrame.\n",
    "\n",
    "- Do basic analysis of domains and point distributions\n",
    "\n",
    "** Bonus **\n",
    "\n",
    "Automatically find the next \"more link\" and mine the next page(s) until none exist.  Logically, you can each page with this pseudo code:\n",
    "\n",
    "1. Does the next link exist (a tag with text == \"More\")\n",
    "1. Fetch URL, prepended with domain (datatau.com/(extracted link here))\n",
    "1. Parse the page with `Selector(text=HTML).xpath('').extract()` to find the elements\n",
    "1. Add to dataframe\n",
    "\n",
    "_Note:  You might want to set a limit something like 2-3 total requests per attempt to avoid unecessary transfer_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm goiing to parse:  http://www.datatau.com\n"
     ]
    }
   ],
   "source": [
    "import requests, numpy as np\n",
    "\n",
    "master_data = {}\n",
    "\n",
    "def parse_url(url, data=False):\n",
    "    print \"I'm goiing to parse: \", url\n",
    "    \n",
    "    #Establish Pull\n",
    "    response = requests.get(url)\n",
    "    HTML = response.text\n",
    "    \n",
    "    #Parse Data\n",
    "    titles  = Selector(text=HTML).xpath(\"//td[@class='title']/a/text()\").extract()\n",
    "    urls    = Selector(text=HTML).xpath(\"//td[@class='title']/a/@href\").extract()\n",
    "    domains = Selector(text=HTML).xpath(\"//td[@class='title']/span[@class='comhead']/text()\").extract() \n",
    "    points  = Selector(text=HTML).xpath(\"//td[@class='subtext']/span/text()\").extract()\n",
    "    author = Selector(text=HTML).xpath(\"//td[@class='subtext']/a[1]/text()\").extract()\n",
    "    comments = Selector(text=HTML).xpath(\"//td[@class='subtext']/a[2]/text()\").extract()\n",
    "\n",
    "    #Place in array (accunt for 'More' link at end of Titles and URLs)\n",
    "    master_data = dict({\n",
    "        'Titles': titles[:30],\n",
    "        'URLs': urls[:30],\n",
    "        'Domains': domains,\n",
    "        'Points': points,\n",
    "        'Author': author,\n",
    "        'Comments': comments\n",
    "    })\n",
    "    \n",
    "    #return data\n",
    "    return master_data\n",
    "\n",
    "master_data = pd.DataFrame(parse_url(\"http://www.datatau.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Domains</th>\n",
       "      <th>Points</th>\n",
       "      <th>Titles</th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dacort</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(googleblog.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Open sourcing Embedding Projector: a tool for ...</td>\n",
       "      <td>https://research.googleblog.com/2016/12/open-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mmaia</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(infoq.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>ETL Is Dead, Long-live Streams</td>\n",
       "      <td>https://www.infoq.com/presentations/etl-streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nickhould</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(jeannicholashould.com)</td>\n",
       "      <td>10 points</td>\n",
       "      <td>Tidy Data in Python</td>\n",
       "      <td>http://www.jeannicholashould.com/tidy-data-in-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asiaticchamoir</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(openai.com)</td>\n",
       "      <td>5 points</td>\n",
       "      <td>OpenAI Universe</td>\n",
       "      <td>https://openai.com/blog/universe/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_kulte</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(dia.co)</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Estimating an Average Without AVG()</td>\n",
       "      <td>https://making.dia.co/estimating-an-average-wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mwakanosya</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>4 points</td>\n",
       "      <td>NIPS Day 1 with Plug and Play Generative Networks</td>\n",
       "      <td>https://blog.insightdatascience.com/nips-2016-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>randyzwitch</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(jowanza.com)</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Time-series missing data imputation in Apache ...</td>\n",
       "      <td>http://www.jowanza.com/post/154094307399/time-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jmount</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(win-vector.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Using replyr::let to Parameterize dplyr Expres...</td>\n",
       "      <td>http://www.win-vector.com/blog/2016/12/using-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dwhitena</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Analyzing the 2016 World Chess Championship</td>\n",
       "      <td>https://medium.com/pachyderm-data/analyzing-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m31</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(flyelephant.net)</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Data Science Tools Survey 2016</td>\n",
       "      <td>https://flyelephant.net/datasciencetools2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jejo</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(shapeofdata.wordpress.com)</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Shape of Data: Properties of Interpretability</td>\n",
       "      <td>https://shapeofdata.wordpress.com/2016/12/05/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yovyom</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(chatbotslife.com)</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Ultimate guide to build Chatbots</td>\n",
       "      <td>https://chatbotslife.com/ultimate-guide-to-lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>actiTIME_Team</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(actiplans.com)</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Attendance management: A way to reduce costs a...</td>\n",
       "      <td>https://www.actiplans.com/attendance-managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ceperez</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Rethinking Generalization for Deep Learning</td>\n",
       "      <td>https://medium.com/intuitionmachine/rethinking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zeroviscosity</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>(oreilly.com)</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Go for Data Science</td>\n",
       "      <td>https://www.oreilly.com/ideas/data-science-gop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bohemienne</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Deep Learning the stock market</td>\n",
       "      <td>https://medium.com/@TalPerry/deep-learning-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sebastien_dery</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Dawn of Artificial Intelligence - The First Co...</td>\n",
       "      <td>https://medium.com/@sderymail/the-dawn-of-arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>thang</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(ethanrosenthal.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Using Keras' Pretrained Neural Networks for Vi...</td>\n",
       "      <td>http://blog.ethanrosenthal.com/2016/12/05/reca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rk</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(azure.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Azure Notebooks</td>\n",
       "      <td>https://notebooks.azure.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jcbozonier</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(posthaven.com)</td>\n",
       "      <td>2 points</td>\n",
       "      <td>No control, no baseline, no problem.</td>\n",
       "      <td>http://databozo.posthaven.com/no-control-no-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tygrysminsk</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>10 points</td>\n",
       "      <td>A short guide to learn neural networks, and ge...</td>\n",
       "      <td>https://medium.com/@sergeyenin/a-short-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rogerh91</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(springboard.com)</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Data Scientist Job Description: How to navigat...</td>\n",
       "      <td>https://www.springboard.com/blog/data-scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pmigdal</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>11 points</td>\n",
       "      <td>Modern Pandas (Part 2): Method Chaining</td>\n",
       "      <td>https://tomaugspurger.github.io/method-chainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rouse</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(amitkaps.com)</td>\n",
       "      <td>6 points</td>\n",
       "      <td>What is a data portrait? A case study using In...</td>\n",
       "      <td>http://amitkaps.com/data-portraits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sebastien_dery</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>9 points</td>\n",
       "      <td>On the Wrong Side of Algorithms - Discriminati...</td>\n",
       "      <td>https://medium.com/@sderymail/on-the-wrong-sid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>benfrederickson</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(benfrederickson.com)</td>\n",
       "      <td>17 points</td>\n",
       "      <td>An Interactive Tutorial on Numerical Optimization</td>\n",
       "      <td>http://www.benfrederickson.com/numerical-optim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jhoechtl</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(dgraph.io)</td>\n",
       "      <td>4 points</td>\n",
       "      <td>DGraph: A Scalable, Distributed, Low Latency, ...</td>\n",
       "      <td>https://dgraph.io/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EugeniyaKorotya</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(da-14.com)</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Databases In Details: How To Choose The Right ...</td>\n",
       "      <td>https://da-14.com/blog/databases-details-how-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jahan</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(aioptify.com)</td>\n",
       "      <td>13 points</td>\n",
       "      <td>Top 22 Python Programming Books</td>\n",
       "      <td>http://www.aioptify.com/top-python-programming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tmostak</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Visualizing 341M geo-located tweets. Powered b...</td>\n",
       "      <td>https://www.mapd.com/demos/tweetmap/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author    Comments                        Domains     Points  \\\n",
       "0            dacort     discuss              (googleblog.com)    2 points   \n",
       "1             mmaia     discuss                   (infoq.com)    2 points   \n",
       "2         nickhould  2 comments       (jeannicholashould.com)   10 points   \n",
       "3    asiaticchamoir     discuss                  (openai.com)    5 points   \n",
       "4            _kulte     discuss                      (dia.co)    4 points   \n",
       "5        mwakanosya     discuss      (insightdatascience.com)    4 points   \n",
       "6       randyzwitch     discuss                 (jowanza.com)    4 points   \n",
       "7            jmount   1 comment              (win-vector.com)    2 points   \n",
       "8          dwhitena     discuss                  (medium.com)    2 points   \n",
       "9               m31     discuss             (flyelephant.net)    5 points   \n",
       "10             jejo     discuss   (shapeofdata.wordpress.com)    3 points   \n",
       "11           yovyom     discuss            (chatbotslife.com)    4 points   \n",
       "12    actiTIME_Team  2 comments               (actiplans.com)    3 points   \n",
       "13          ceperez     discuss                  (medium.com)    4 points   \n",
       "14    zeroviscosity  3 comments                 (oreilly.com)    5 points   \n",
       "15       bohemienne     discuss                  (medium.com)    4 points   \n",
       "16   sebastien_dery     discuss                  (medium.com)    2 points   \n",
       "17            thang     discuss          (ethanrosenthal.com)    2 points   \n",
       "18               rk     discuss                   (azure.com)    2 points   \n",
       "19       jcbozonier     discuss               (posthaven.com)    2 points   \n",
       "20      tygrysminsk   1 comment                  (medium.com)   10 points   \n",
       "21         Rogerh91     discuss             (springboard.com)    9 points   \n",
       "22          pmigdal     discuss                   (github.io)   11 points   \n",
       "23            rouse     discuss                (amitkaps.com)    6 points   \n",
       "24   sebastien_dery   1 comment                  (medium.com)    9 points   \n",
       "25  benfrederickson   1 comment         (benfrederickson.com)   17 points   \n",
       "26         jhoechtl     discuss                   (dgraph.io)    4 points   \n",
       "27  EugeniyaKorotya     discuss                   (da-14.com)    3 points   \n",
       "28            jahan   1 comment                (aioptify.com)   13 points   \n",
       "29          tmostak  3 comments                    (mapd.com)    5 points   \n",
       "\n",
       "                                               Titles  \\\n",
       "0   Open sourcing Embedding Projector: a tool for ...   \n",
       "1                      ETL Is Dead, Long-live Streams   \n",
       "2                                 Tidy Data in Python   \n",
       "3                                    OpenAI Universe    \n",
       "4                 Estimating an Average Without AVG()   \n",
       "5   NIPS Day 1 with Plug and Play Generative Networks   \n",
       "6   Time-series missing data imputation in Apache ...   \n",
       "7   Using replyr::let to Parameterize dplyr Expres...   \n",
       "8         Analyzing the 2016 World Chess Championship   \n",
       "9                      Data Science Tools Survey 2016   \n",
       "10      Shape of Data: Properties of Interpretability   \n",
       "11                   Ultimate guide to build Chatbots   \n",
       "12  Attendance management: A way to reduce costs a...   \n",
       "13        Rethinking Generalization for Deep Learning   \n",
       "14                                Go for Data Science   \n",
       "15                     Deep Learning the stock market   \n",
       "16  Dawn of Artificial Intelligence - The First Co...   \n",
       "17  Using Keras' Pretrained Neural Networks for Vi...   \n",
       "18                                    Azure Notebooks   \n",
       "19               No control, no baseline, no problem.   \n",
       "20  A short guide to learn neural networks, and ge...   \n",
       "21  Data Scientist Job Description: How to navigat...   \n",
       "22            Modern Pandas (Part 2): Method Chaining   \n",
       "23  What is a data portrait? A case study using In...   \n",
       "24  On the Wrong Side of Algorithms - Discriminati...   \n",
       "25  An Interactive Tutorial on Numerical Optimization   \n",
       "26  DGraph: A Scalable, Distributed, Low Latency, ...   \n",
       "27  Databases In Details: How To Choose The Right ...   \n",
       "28                    Top 22 Python Programming Books   \n",
       "29  Visualizing 341M geo-located tweets. Powered b...   \n",
       "\n",
       "                                                 URLs  \n",
       "0   https://research.googleblog.com/2016/12/open-s...  \n",
       "1     https://www.infoq.com/presentations/etl-streams  \n",
       "2   http://www.jeannicholashould.com/tidy-data-in-...  \n",
       "3                   https://openai.com/blog/universe/  \n",
       "4   https://making.dia.co/estimating-an-average-wi...  \n",
       "5   https://blog.insightdatascience.com/nips-2016-...  \n",
       "6   http://www.jowanza.com/post/154094307399/time-...  \n",
       "7   http://www.win-vector.com/blog/2016/12/using-r...  \n",
       "8   https://medium.com/pachyderm-data/analyzing-th...  \n",
       "9        https://flyelephant.net/datasciencetools2016  \n",
       "10  https://shapeofdata.wordpress.com/2016/12/05/p...  \n",
       "11  https://chatbotslife.com/ultimate-guide-to-lev...  \n",
       "12  https://www.actiplans.com/attendance-managemen...  \n",
       "13  https://medium.com/intuitionmachine/rethinking...  \n",
       "14  https://www.oreilly.com/ideas/data-science-gop...  \n",
       "15  https://medium.com/@TalPerry/deep-learning-the...  \n",
       "16  https://medium.com/@sderymail/the-dawn-of-arti...  \n",
       "17  http://blog.ethanrosenthal.com/2016/12/05/reca...  \n",
       "18                        https://notebooks.azure.com  \n",
       "19  http://databozo.posthaven.com/no-control-no-ba...  \n",
       "20  https://medium.com/@sergeyenin/a-short-guide-t...  \n",
       "21  https://www.springboard.com/blog/data-scientis...  \n",
       "22  https://tomaugspurger.github.io/method-chainin...  \n",
       "23                 http://amitkaps.com/data-portraits  \n",
       "24  https://medium.com/@sderymail/on-the-wrong-sid...  \n",
       "25  http://www.benfrederickson.com/numerical-optim...  \n",
       "26                                 https://dgraph.io/  \n",
       "27  https://da-14.com/blog/databases-details-how-c...  \n",
       "28  http://www.aioptify.com/top-python-programming...  \n",
       "29               https://www.mapd.com/demos/tweetmap/  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_results.append({\n",
    "        'title': row.xpath(\"./a/text()\").extract()[0],\n",
    "        'link_details': link_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.datatau.com\"\n",
    "response = requests.get(url)\n",
    "HTML = response.text\n",
    "#print HTML[:150], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles_list = []\n",
    "titles = Selector(text=HTML).xpath(\"//td[@class='title']/a/text()\").extract()\n",
    "for title in titles:\n",
    "    titles_list.append(title)\n",
    "#print titles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domain_list = []\n",
    "\n",
    "domains = Selector(text=HTML).xpath(\"//td[@class='title']/span[@class='comhead']\").extract()\n",
    "for domain in domains:\n",
    "    domain_list.append(domain)\n",
    "#print url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_list = []\n",
    "\n",
    "urls = Selector(text=HTML).xpath(\"//td[@class='title']/a/@href\").extract()\n",
    "# for url in urls:\n",
    "#     url_list.append(url)\n",
    "#print urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'2 points', u'2 points', u'10 points', u'5 points', u'4 points', u'4 points', u'4 points', u'2 points', u'2 points', u'5 points', u'3 points', u'4 points', u'3 points', u'4 points', u'5 points', u'4 points', u'2 points', u'2 points', u'2 points', u'2 points', u'10 points', u'9 points', u'11 points', u'6 points', u'9 points', u'17 points', u'4 points', u'3 points', u'5 points', u'13 points']\n"
     ]
    }
   ],
   "source": [
    "point_list = []\n",
    "points = Selector(text=HTML).xpath(\"//td[@class='subtext']/span/text()\").extract()\n",
    "# for point in points:\n",
    "#     point_list.append(point)\n",
    "print points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "web_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print len(titles_list)\n",
    "print len(url_list)\n",
    "\n",
    "# web_data_dict = {\n",
    "#     'Titles': titles_list,\n",
    "#     'URLs': url_list,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-84bd0ea9e3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweb_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweb_data_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    222\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    223\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5229\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5231\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5233\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   5277\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5278\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5279\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "web_data = pd.DataFrame(web_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Open sourcing Embedding Projector: a tool for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETL Is Dead, Long-live Streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tidy Data in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenAI Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estimating an Average Without AVG()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles\n",
       "0  Open sourcing Embedding Projector: a tool for ...\n",
       "1                     ETL Is Dead, Long-live Streams\n",
       "2                                Tidy Data in Python\n",
       "3                                   OpenAI Universe \n",
       "4                Estimating an Average Without AVG()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html data-language=\"english\" itemscope itemtype=\"http://schema.org/SearchResultsPage\" lang=\"en\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\" />\n",
      "\t<t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"http://sanfrancisco.locanto.com/Musical-Instruments/415/1/\"\n",
    "response = requests.get(url)\n",
    "HTML = response.text\n",
    "#print HTML[:150], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'    $22.99', u'   $249.99', u'   $529.99', u'   $249.99', u'    $21.99', u'    $89.99', u'   $699.99', u'    $69.99', u'     $5.99', u'   $169.99', u'    $59.99', u'   $159.95', u'    $39.99', u'    $19.99', u'   $399.99', u'    $12.99', u'    $19.99', u'    $33.99', u'    $16.95', u'    $40.99', u'    $59.99', u'      $249', u'   $229.95', u'    $29.99']\n"
     ]
    }
   ],
   "source": [
    "price_list = []\n",
    "prices = Selector(text=HTML).xpath(\"//div/strong/text()\").extract()\n",
    "for price in prices:\n",
    "    price_list.append(price)\n",
    "print price_list[:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    $22.99 0\n",
      "   $249.99 1\n",
      "   $529.99 2\n",
      "   $249.99 3\n",
      "    $21.99 4\n",
      "    $89.99 5\n",
      "   $699.99 6\n",
      "    $69.99 7\n",
      "     $5.99 8\n",
      "   $169.99 9\n",
      "    $59.99 10\n",
      "   $159.95 11\n",
      "    $39.99 12\n",
      "    $19.99 13\n",
      "   $399.99 14\n",
      "    $12.99 15\n",
      "    $19.99 16\n",
      "    $33.99 17\n",
      "    $16.95 18\n",
      "    $40.99 19\n",
      "    $59.99 20\n",
      "      $249 21\n",
      "   $229.95 22\n",
      "    $29.99 23\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in price_list:\n",
    "    print i, counter\n",
    "    counter += 1\n",
    "    if counter == 24:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_list = []\n",
    "descs = Selector(text=HTML).xpath(\"//div/strong/text()\").extract()\n",
    "for desc in descs:\n",
    "    desc_list.append(desc)\n",
    "print descs_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "imgs = Selector(text=HTML).xpath(\"//img[@src]\").extract()\n",
    "for img in imgs:\n",
    "    img_list.append(img)\n",
    "\n",
    "for img in img_list:\n",
    "    print img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
