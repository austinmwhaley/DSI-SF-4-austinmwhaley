{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 15px;\">\n",
    "\n",
    "## Bayesian statistics and baseball data\n",
    "\n",
    "Week 9 | 4.2\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "To review the general setup for Bayesian distribution modeling, we have:\n",
    "\n",
    "### $$P\\left(\\;model\\;|\\;data\\;\\right) = \\frac{P\\left(\\;data\\;|\\;model\\;\\right)}{P(\\;data\\;)} P\\left(\\;model\\;\\right)$$\n",
    "\n",
    "Which can also be written as:\n",
    "\n",
    "### $$posterior = likelihood * prior$$\n",
    "\n",
    "*Where the posterior is an update of our prior belief, given the data observed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Write functions to calculate the binomial likelihood and log likelihood\n",
    "\n",
    "The binomial likelihood is defined as:\n",
    "\n",
    "### $$likelihood(n,k\\;|\\;p) = \\binom{n}{k}p^k(1-p)^{n-k}$$\n",
    "\n",
    "Because the original can break easily with high counts, the log likelihood is often used in its place:\n",
    "\n",
    "### $$ln(likelihood) = ln\\binom{n}{k}+k*ln(p)+(n-k)*ln(1-p)$$\n",
    "\n",
    "Your functions should:\n",
    "\n",
    "1. Take a probability (p), number of trials (n), and number of successes (k)\n",
    "2. Return a likelihood for the trials and successes at that probability \n",
    "\n",
    "Recall that `np.log()` can be used for natural log. `np.exp()` is useful for getting your likelihood out when the log-likelihood function is done computing. `scipy.misc.comb()` can get the combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(n, k, p):\n",
    "    return comb(n, k) * (p**k) * (1 - p)**(n-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loglikelihood(n, k, p):\n",
    "    return np.log(comb(n, k)) + k * np.log(p) + (n-k) * np.log(1-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate likelihoods using both functions for:\n",
    "\n",
    "    n=10, k=3\n",
    "    n=10, k=7\n",
    "    n=20, k=15\n",
    "    n=50, k=9\n",
    "    n=70, k=50\n",
    "    n=100, k=96\n",
    "    \n",
    "For probabilities:\n",
    "\n",
    "    p = [0.05, 0.5, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nks = [\n",
    "    [10, 3],\n",
    "    [10, 7],\n",
    "    [20, 15],\n",
    "    [50, 9],\n",
    "    [70, 50],\n",
    "    [100, 96]\n",
    "]\n",
    "\n",
    "ps = [0.05, 0.5, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10 || k = 3\n",
      "p = 0.05 likelihood = 0.0104750594414\n",
      "p = 0.5 likelihood = 0.1171875\n",
      "p = 0.95 likelihood = 8.037890625e-08\n",
      "---------------------------------\n",
      "\n",
      "n = 10 || k = 7\n",
      "p = 0.05 likelihood = 8.037890625e-08\n",
      "p = 0.5 likelihood = 0.1171875\n",
      "p = 0.95 likelihood = 0.0104750594414\n",
      "---------------------------------\n",
      "\n",
      "n = 20 || k = 15\n",
      "p = 0.05 likelihood = 3.66110218964e-16\n",
      "p = 0.5 likelihood = 0.0147857666016\n",
      "p = 0.95 likelihood = 0.00224464601012\n",
      "---------------------------------\n",
      "\n",
      "n = 50 || k = 9\n",
      "p = 0.05 likelihood = 0.000597421393598\n",
      "p = 0.5 likelihood = 2.22527214433e-06\n",
      "p = 0.95 likelihood = 7.18067945185e-45\n",
      "---------------------------------\n",
      "\n",
      "n = 70 || k = 50\n",
      "p = 0.05 likelihood = 5.15439703965e-49\n",
      "p = 0.5 likelihood = 0.000137121592955\n",
      "p = 0.95 likelihood = 1.18791645303e-10\n",
      "---------------------------------\n",
      "\n",
      "n = 100 || k = 96\n",
      "p = 0.05 likelihood = 4.03122093054e-119\n",
      "p = 0.5 likelihood = 3.09330110308e-24\n",
      "p = 0.95 likelihood = 0.17814264157\n",
      "---------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, k in nks:\n",
    "    print 'n =',n, '||', 'k =',k\n",
    "    for p in ps:\n",
    "        print 'p =', p, 'likelihood =',likelihood(n, k, p)\n",
    "    print '---------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10 || k = 3\n",
      "p = 0.05 likelihood = 4.55875813859\n",
      "p = 0.5 likelihood = 2.14398006282\n",
      "p = 0.95 likelihood = 16.3365140553\n",
      "---------------------------------\n",
      "\n",
      "n = 10 || k = 7\n",
      "p = 0.05 likelihood = 16.3365140553\n",
      "p = 0.5 likelihood = 2.14398006282\n",
      "p = 0.95 likelihood = 4.55875813859\n",
      "---------------------------------\n",
      "\n",
      "n = 20 || k = 15\n",
      "p = 0.05 likelihood = 35.5435972411\n",
      "p = 0.5 likelihood = 4.21409027707\n",
      "p = 0.95 likelihood = 6.09920744945\n",
      "---------------------------------\n",
      "\n",
      "n = 50 || k = 9\n",
      "p = 0.05 likelihood = 7.42288784165\n",
      "p = 0.5 likelihood = 13.0156313378\n",
      "p = 0.95 likelihood = 101.644935175\n",
      "---------------------------------\n",
      "\n",
      "n = 70 || k = 50\n",
      "p = 0.05 likelihood = 111.186819412\n",
      "p = 0.5 likelihood = 8.89464248595\n",
      "p = 0.95 likelihood = 22.8536500372\n",
      "---------------------------------\n",
      "\n",
      "n = 100 || k = 96\n",
      "p = 0.05 likelihood = 272.613556776\n",
      "p = 0.5 likelihood = 54.132803393\n",
      "p = 0.95 likelihood = 1.72517069247\n",
      "---------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, k in nks:\n",
    "    print 'n =',n, '||', 'k =',k\n",
    "    for p in ps:\n",
    "        print 'p =', p, 'likelihood =', (-1*loglikelihood(n, k, p))\n",
    "    print '---------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The beta distribution\n",
    "\n",
    "[The beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) is the appropriate prior distribution for modeling Bernoulli processes (occurrences of successes or failures, etc.). It is a model of the random behavior of data related to percentages, rates, proportions, etc.\n",
    "\n",
    "The beta distribution takes two parameters: $Beta(\\alpha,\\beta)$\n",
    "\n",
    "The $\\alpha$ or **alpha** parameter can be thought of as the number of `successes + 1`\n",
    "\n",
    "The $\\beta$ or **beta** parameter can be thought of as the number of `failures + 1`\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Beta_distribution_pdf.svg/650px-Beta_distribution_pdf.svg.png\" alt=\"betapdf\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Plot beta probability density functions\n",
    "\n",
    "Use the `scipy.stats.beta` object to calculate the probability density of the beta function across a range of points.\n",
    "\n",
    "Make one plot for each of the n, k pairs you calculated the likelihood for above (converting them into success, failure pairs for the alpha, beta parameters). Plot the probability density function values across a range of probabilities between 0 and 1.\n",
    "\n",
    "http://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.stats.beta.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The beta and \"conjugate priors\"\n",
    "\n",
    "The beta distribution is a **conjugate prior** for the binomial (and the beta) distributions. What does this mean?\n",
    "\n",
    "Take the calculation of the posterior distribution with a binomial likelihood function (any binary outcome data):\n",
    "\n",
    "### $$\\text{beta posterior} = \\text{binomial likelihood} * \\text{beta prior}$$\n",
    "\n",
    "**The beta distribution being a \"conjugate prior\" of the binomial likelihood guarantees that the posterior distribution will also be a beta distribution.**\n",
    "\n",
    "This is also true when the likelihood is a beta likelihood:\n",
    "\n",
    "### $$\\text{beta posterior} = \\text{beta likelihood} * \\text{beta prior}$$\n",
    "\n",
    "Again, the posterior is guaranteed to be a beta distribution.\n",
    "\n",
    "Conjugate priors are extremely useful for calculating posteriors directly. Unfortunately, in many modeling scenarios we do not have the convenience of a conjugate prior. This is where methods like Markov Chain Monte Carlo (MCMC) will come into play down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bayesian analysis of batting averages\n",
    "\n",
    "Load in the simple batting avergage data for players below. There are just four fields in the dataset: the player's name, their times at bat, their hits, and their batting average.\n",
    "\n",
    "[This section of the lab is a partial replication of this exercise in R, if you're interested.](https://www.r-bloggers.com/understanding-empirical-bayes-estimation-using-baseball-statistics/) But I took out the \"empirical bayes\" part because it's not technically a \"correct\" interpretation of Bayesian statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hits = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-4/datasets/baseball_hits/career_hits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Find the top and bottom 3 hitters according to their average.\n",
    "\n",
    "What is wrong with using the average to find the 3 best and 3 worst hitters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Set up prior belief for hits\n",
    "\n",
    "[After doing a quick search online](https://www.google.com/search?q=average+batting+average+for+players+mlb&oq=average+batting+average+for+players+mlb&aqs=chrome..69i57j0.7373j0j4&sourceid=chrome&ie=UTF-8), it looks like the overall batting average for MLB baseball players is around 0.260.\n",
    "\n",
    "Let's make it simple and say that our prior belief is: out of 100 at-bats we have seen 26 hits. Set up a beta distribution with `alpha=27` and `beta=75`. Plot it with the function from above.\n",
    "\n",
    "This is our distribution of beliefs on the batting average (probability of hit while at-bat) for MLB players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Calculate the Maximum A Posteriori (MAP) estimate of players' batting averages\n",
    "\n",
    "The Maximum A Posteriori (MAP) estimate is counterpart of the Maximum Likelihood Estimate (MLE) of a statistic that is  used in frequentist statistics. It is the mode of a posterior distribution for a statistical parameter or model.\n",
    "\n",
    "In our case, the MAP estimate for our players' batting averages will be the mode of the posterior beta distribution we get from updating our prior distribution with their at-bats and hits.\n",
    "\n",
    "---\n",
    "\n",
    "If you're interested in the math of updating the beta distribution and conjugate priors ([see this website for an overview](https://alexanderetz.com/2015/07/25/understanding-bayes-updating-priors-via-the-likelihood/)). \n",
    "\n",
    "We need to update our beta distribution prior belief about batting averages with a player's at-bat and hit information to give us a _new_ beta posterior distribution for that player's batting average. \n",
    "\n",
    "Luckily, with the beta distribution the update is just a matter of adding in our new observations to the alpha and beta parameters of the distribution, where alpha is the number of hits and beta is the number of misses/strikes:\n",
    "\n",
    "    observed_hits = n_hits\n",
    "    observed_misses = n_misses\n",
    "    beta_prior = Beta(prior_hits, prior_misses)\n",
    "    beta_posterior = Beta(prior_hits + n_nits + 1, prior_misses + n_misses + 1)\n",
    "    \n",
    "This process will also be useful in the context of A/B testing, which we will look at later on.\n",
    "\n",
    "For each player, update the prior to the posterior distribution and calculate the mode of the distribution. The mode of a beta distribution is conveniently defined:\n",
    "\n",
    "### $$ \\frac{\\alpha - 1}{\\alpha + \\beta -2} $$\n",
    "\n",
    "Which means we don't even really need to use scipy's beta distribution function at all. Just calculate the new alpha (hits) and beta (misses) for each player's posterior beta distribution and plug them into the formula above to get the MAP estimate of batting average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. Look up the top and bottom batters according to the MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8. Plot the batting average against the MAP batting average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
