{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 4\n",
    "\n",
    "###  Big Query, SQL, Classification\n",
    "\n",
    "---\n",
    "\n",
    "### The Data\n",
    "\n",
    "There are 5 individual tables that have the information, contained in a Google BigQuery database.  The setup info for BigQuery is located on our DSI wiki.  You will have to query with SQL, the dataset in order to complete this project.\n",
    "\n",
    "The tables, with cooresonding attributes that exist are:\n",
    "\n",
    "### businesses\n",
    "- business_id: unique business identifier\n",
    "- name: name of the business\n",
    "- review_count: number of reviews per business\n",
    "- city: city business resides in\n",
    "- stars: average rating\n",
    "- categories: categories the business falls into (can be one or multiple)\n",
    "- latitude\n",
    "- longitude\n",
    "- neighborhoods: neighborhoods business belongs to\n",
    "- variable: \"property\" of the business (a tag)\n",
    "- value: True/False for the property\n",
    "\n",
    "### reviews\n",
    "- user_id: unique user identifier\n",
    "- review_id: unique review identifier\n",
    "- votes.cool: how many thought the review was \"cool\"\n",
    "- business_id: unique business id the review is for\n",
    "- votes.funny: how many thought the review was funny\n",
    "- stars: rating given\n",
    "- date: date of review\n",
    "- votes.useful: how many thought the review was useful\n",
    "- ... 100 columns of counts of most common 2 word phrases that appear in reviews in this review\n",
    "\n",
    "### users\n",
    "- yelping_since: signup date\n",
    "- compliments.plain: # of compliments \"plain\"\n",
    "- review_count: # of reviews:\n",
    "- compliments.cute: total # of compliments \"cute\"\n",
    "- compliments.writer: # of compliments \"writer\"\n",
    "- compliments.note: # of compliments \"note\" (not sure what this is)\n",
    "- compliments.hot: # of compliments \"hot\" (?)\n",
    "- compliments.cool: # of compliments \"cool\"\n",
    "- compliments.profile: # of compliments \"profile\"\n",
    "- average_stars: average rating\n",
    "- compliments.more: # of compliments \"more\"\n",
    "- elite: years considered \"elite\"\n",
    "- name: user's name\n",
    "- user_id: unique user id\n",
    "- votes.cool: # of votes \"cool\"\n",
    "- compliments.list: # of compliments \"list\"\n",
    "- votes.funny: # of compliments \"funny\"\n",
    "- compliments.photos: # of compliments \"photos\"\n",
    "- compliments.funny: # of compliments \"funny\"\n",
    "- votes.useful: # of votes \"useful\"\n",
    "\n",
    "### checkins\n",
    "- business_id: unique business identifier\n",
    "- variable: day-time identifier of checkins (0-0 is Sunday 0:00 - 1:00am,  for example)\n",
    "- value: # of checkins at that time\n",
    "\n",
    "### tips\n",
    "- user_id: unique user identifier\n",
    "- business_id: unique business identifier\n",
    "- likes: likes that the tip has\n",
    "- date: date of tip\n",
    "- ... 100 columns of counts of most common 2 word phrases that appear in tips in this tip\n",
    "\n",
    "\n",
    "The reviews and tips datasets in particular have parsed \"NLP\" columns with counts of 2-word phrases in that review or tip (a \"tip\", it seems, is some kind of smaller review).\n",
    "\n",
    "The user dataset has a lot of columns of counts of different compliments and votes. We're not sure whether the compliments or votes are by the user or for the user.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "If you look at the website, or the full data, you'll see I have removed pieces of the data and cut it down quite a bit. This is to simplify it for this project. Specifically, business are limited to be in these cities:\n",
    "\n",
    "- Phoenix\n",
    "- Surprise\n",
    "- Las Vegas\n",
    "- Waterloo\n",
    "\n",
    "Apparently there is a city called \"Surprise\" in Arizona. \n",
    "\n",
    "Businesses are also restricted to at least be in one of the following categories, because we thought the mix of them was funny:\n",
    "\n",
    "- Airports\n",
    "- Breakfast & Brunch\n",
    "- Bubble Tea\n",
    "- Burgers\n",
    "- Bars\n",
    "- Bakeries\n",
    "- Breweries\n",
    "- Cafes\n",
    "- Candy Stores\n",
    "- Comedy Clubs\n",
    "- Courthouses\n",
    "- Dance Clubs\n",
    "- Fast Food\n",
    "- Museums\n",
    "- Tattoo\n",
    "- Vape Shops\n",
    "- Yoga\n",
    "    \n",
    "---\n",
    "\n",
    "### Project requirements\n",
    "\n",
    "**You will be performing 4 different sections of analysis, like in the last project.**\n",
    "\n",
    "Remember that classification targets are categorical and regression targets are continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Load your dataset(s) / setup / configure GBQ connection\n",
    "\n",
    "---\n",
    "\n",
    "Information about this dataset is located here:\n",
    "\n",
    "\n",
    "**If you haven't done so, setup a project with the Google developer portal, following the directions here: [Getting Started with BigQuery](https://github.com/ga-students/DSI-SF-4/wiki/Getting-Started-with-BigQuery)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Query running...\n",
      "Query done.\n",
      "Processed: 15.2 Mb\n",
      "\n",
      "Retrieving results...\n",
      "  Got page: 1; 12.0% done. Elapsed 11.34 s.\n",
      "  Got page: 2; 23.0% done. Elapsed 16.8 s.\n",
      "  Got page: 3; 35.0% done. Elapsed 22.63 s.\n",
      "  Got page: 4; 46.0% done. Elapsed 29.72 s.\n",
      "  Got page: 5; 58.0% done. Elapsed 34.28 s.\n",
      "  Got page: 6; 69.0% done. Elapsed 39.29 s.\n",
      "  Got page: 7; 81.0% done. Elapsed 45.19 s.\n",
      "  Got page: 8; 92.0% done. Elapsed 50.78 s.\n",
      "  Got page: 9; 100.0% done. Elapsed 54.76 s.\n",
      "Got 144206 rows.\n",
      "\n",
      "Total time taken 66.36 s.\n",
      "Finished at 2016-12-18 21:25:28.\n",
      "--DONE--\n"
     ]
    }
   ],
   "source": [
    "#Businesses, Checkins, Reviews, Tips, Users\n",
    "\n",
    "project_id = \"bigquery-dsi-awhaley\"\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM [bigquery-dsi-dave:yelp_arizona.users]\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_gbq(sql, project_id=project_id)\n",
    "print '--DONE--'\n",
    "#df.to_csv('/Users/austinwhaley/Desktop/DSI-SF-4-austinmwhaley/uber-pickups-in-new-york-city/bigquery-dsi-dave:yelp_arizona.reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>compliments_plain</th>\n",
       "      <th>review_count</th>\n",
       "      <th>compliments_cute</th>\n",
       "      <th>compliments_writer</th>\n",
       "      <th>fans</th>\n",
       "      <th>compliments_note</th>\n",
       "      <th>compliments_hot</th>\n",
       "      <th>compliments_cool</th>\n",
       "      <th>compliments_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>compliments_more</th>\n",
       "      <th>elite</th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>compliments_list</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>compliments_photos</th>\n",
       "      <th>compliments_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Scott</td>\n",
       "      <td>dMeSxE7S6Yxhz3cBgd6Sjw</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Diego</td>\n",
       "      <td>c-e0BxGy3eNtKzKDrrHyGw</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  yelping_since  compliments_plain  review_count  compliments_cute  \\\n",
       "0       2015-01                NaN             1               NaN   \n",
       "1       2015-01                NaN             1               NaN   \n",
       "\n",
       "   compliments_writer  fans  compliments_note  compliments_hot  \\\n",
       "0                 NaN     0               NaN              NaN   \n",
       "1                 NaN     0               NaN              NaN   \n",
       "\n",
       "   compliments_cool  compliments_profile      ...       compliments_more  \\\n",
       "0               NaN                  NaN      ...                    NaN   \n",
       "1               NaN                  NaN      ...                    NaN   \n",
       "\n",
       "   elite   name                 user_id votes_cool  compliments_list  \\\n",
       "0     []  Scott  dMeSxE7S6Yxhz3cBgd6Sjw          0              None   \n",
       "1     []  Diego  c-e0BxGy3eNtKzKDrrHyGw          0              None   \n",
       "\n",
       "  votes_funny  compliments_photos compliments_funny  votes_useful  \n",
       "0           0                None               NaN             0  \n",
       "1           0                None               NaN             0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\xf6' in position 1: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-85bc09873cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/austinwhaley/Desktop/DSI-SF-4-austinmwhaley/uber-pickups-in-new-york-city/bigquery-dsi-dave:yelp_arizona.users.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1344\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1676\u001b[0m                                         quoting=self.quoting)\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;31m# from collections import namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/lib.pyx\u001b[0m in \u001b[0;36mpandas.lib.write_csv_rows (pandas/lib.c:19472)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xf6' in position 1: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "df.to_csv('/Users/austinwhaley/Desktop/DSI-SF-4-austinmwhaley/uber-pickups-in-new-york-city/bigquery-dsi-dave:yelp_arizona.users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'business_id', u'name', u'review_count', u'city', u'stars',\n",
       "       u'categories', u'latitude', u'longitude', u'neighborhoods', u'variable',\n",
       "       u'value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Las Vegas    93818\n",
       "Phoenix      53279\n",
       "Surprise      2974\n",
       "Waterloo      2761\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['city'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Constructing a \"profile\" for Las Vegas\n",
    "\n",
    "---\n",
    "\n",
    "Yelp is interested in building out what they are calling \"profiles\" for cities. They want you to start with just Las Vegas to see what a prototype of this would look like. Essentially, they want to know what makes Las Vegas distinct from the other four.\n",
    "\n",
    "Use the data you have to predict Las Vegas from the other variables you have. You should not be predicting the city from any kind of location data or other data perfectly associated with that city (or another city).\n",
    "\n",
    "You may use any classification algorithm you deem appropriate, or even multiple models. You should:\n",
    "\n",
    "1. Build at least one model predicting Las Vegas vs. the other cities.\n",
    "- Validate your model(s).\n",
    "- Interpret and visualize, in some way, the results.\n",
    "- Write up a \"profile\" for Las Vegas. This should be a writeup converting your findings from the model(s) into a human-readable description of the city.\n",
    "\n",
    "*Research location data to find the city targets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bus = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = bus.drop(['business_id', 'city', 'latitude', 'longitude'], 1)\n",
    "X = bus[['categories', 'stars']]\n",
    "y = bus['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_list = []\n",
    "for i in bus['categories']:\n",
    "    try:\n",
    "        category_list.extend(i.split(', '))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "category_list = np.unique(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_category(series_value, column_name=None):\n",
    "    try:\n",
    "        if column_name in series_value:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austinwhaley/anaconda/envs/dsi/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for x in category_list:\n",
    "    X[x] = X['categories'].apply(parse_category, column_name=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>stars</th>\n",
       "      <th>\"Women's Clothing\"</th>\n",
       "      <th>'Active Life'</th>\n",
       "      <th>'Active Life']</th>\n",
       "      <th>'Adult Entertainment'</th>\n",
       "      <th>'Afghan'</th>\n",
       "      <th>'Airports']</th>\n",
       "      <th>'Amateur Sports Teams'</th>\n",
       "      <th>'American (New)'</th>\n",
       "      <th>...</th>\n",
       "      <th>['Tapas/Small Plates'</th>\n",
       "      <th>['Tattoo Removal'</th>\n",
       "      <th>['Tattoo'</th>\n",
       "      <th>['Tex-Mex'</th>\n",
       "      <th>['Thai'</th>\n",
       "      <th>['Tobacco Shops'</th>\n",
       "      <th>['Vegetarian'</th>\n",
       "      <th>['Weight Loss Centers'</th>\n",
       "      <th>['Wine Bars'</th>\n",
       "      <th>['Yoga'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Burgers', 'American (Traditional)', 'Sandwic...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Burgers', 'American (Traditional)', 'Sandwic...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Burgers', 'American (Traditional)', 'Sandwic...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories  stars  \\\n",
       "0  ['Burgers', 'American (Traditional)', 'Sandwic...    3.0   \n",
       "1  ['Burgers', 'American (Traditional)', 'Sandwic...    3.0   \n",
       "2  ['Burgers', 'American (Traditional)', 'Sandwic...    3.0   \n",
       "\n",
       "   \"Women's Clothing\"  'Active Life'  'Active Life']  'Adult Entertainment'  \\\n",
       "0                   0              0               0                      0   \n",
       "1                   0              0               0                      0   \n",
       "2                   0              0               0                      0   \n",
       "\n",
       "   'Afghan'  'Airports']  'Amateur Sports Teams'  'American (New)'   ...     \\\n",
       "0         0            0                       0                 0   ...      \n",
       "1         0            0                       0                 0   ...      \n",
       "2         0            0                       0                 0   ...      \n",
       "\n",
       "   ['Tapas/Small Plates'  ['Tattoo Removal'  ['Tattoo'  ['Tex-Mex'  ['Thai'  \\\n",
       "0                      0                  0          0           0        0   \n",
       "1                      0                  0          0           0        0   \n",
       "2                      0                  0          0           0        0   \n",
       "\n",
       "   ['Tobacco Shops'  ['Vegetarian'  ['Weight Loss Centers'  ['Wine Bars'  \\\n",
       "0                 0              0                       0             0   \n",
       "1                 0              0                       0             0   \n",
       "2                 0              0                       0             0   \n",
       "\n",
       "   ['Yoga'  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "\n",
       "[3 rows x 336 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Las Vegas\n",
       "1    Las Vegas\n",
       "2    Las Vegas\n",
       "Name: city, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 20:58:14.139817\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X)\n",
    "print datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152832, 1319)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 20:58:50.795006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "print datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6138635887772195"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = 93818./ 152832.\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76906974  0.76906974  0.76383619  0.75510471  0.7558581 ] \n",
      "\n",
      "0.762587694532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train, y_train)\n",
    "scores = cross_val_score(KNN, X_test, y_test, cv=5)\n",
    "print scores, '\\n'\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method KNeighborsClassifier.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['Target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Las Vegas    93818\n",
       "Phoenix      53279\n",
       "Surprise      2974\n",
       "Waterloo      2761\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phoenix = X[X['Target'] == 'Phoenix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst_phoenix = []\n",
    "for i in phoenix.columns:\n",
    "    try:\n",
    "        lst_phoenix.append([phoenix[i].value_counts()[1], i])\n",
    "    except:\n",
    "        lst_phoenix.append([0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[43271, u\"'Restaurants'\"],\n",
       " [40922, u\"'Restaurants']\"],\n",
       " [18782, u\"'Nightlife'\"],\n",
       " [18200, u\"'Bars'\"],\n",
       " [14110, u\"'Fast Food'\"]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_phoenix = sorted(lst_phoenix, reverse=True)\n",
    "lst_phoenix[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Phoenix--\n",
      "0.436184953847 = Restaurants\n",
      "0.200196124411 = Nightlife\n",
      "0.193992624017 = Bars\n",
      "0.15039757829 = Fast Food\n"
     ]
    }
   ],
   "source": [
    "print '--Phoenix--'\n",
    "print (40922.) / 93818, '= Restaurants'\n",
    "print 18782. / 93818., '= Nightlife'\n",
    "print 18200. / 93818., '= Bars'\n",
    "print 14110. / 93818., '= Fast Food'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "las_vegas = X[X['Target'] == 'Las Vegas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst_vegas = []\n",
    "for i in las_vegas.columns:\n",
    "    try:\n",
    "        lst_vegas.append([las_vegas[i].value_counts()[1], i])\n",
    "    except:\n",
    "        lst_vegas.append([0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[66755, u\"'Restaurants'\"],\n",
       " [63027, u\"'Restaurants']\"],\n",
       " [39881, u\"'Nightlife'\"],\n",
       " [36983, u\"'Bars'\"],\n",
       " [25658, u\"['Bars'\"]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_vegas = sorted(lst_vegas, reverse=True)\n",
    "lst_vegas[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Vegas--93818\n",
      "0.711537231661 = Restaurants\n",
      "0.42508900211 = Nightlife\n",
      "0.394199407363 = Bars\n"
     ]
    }
   ],
   "source": [
    "print '--Vegas--93818'\n",
    "print (66755.) / 93818, '= Restaurants'\n",
    "print 39881. / 93818, '= Nightlife'\n",
    "print (36983.) / 93818, '= Bars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write up a \"profile\" for Las Vegas. \n",
    "This should be a writeup converting your findings from the model(s) into a human-readable description of the city.\n",
    "\n",
    "Used a KNN Model. Cross-Validated it with 5-Folds\n",
    "Looking at the submitted reviews (Las Vegas vs. Phoenix)\n",
    "\n",
    "Looking at the distribution of review categories (what categories the user population chooses to submit reviews on), \n",
    "there is a trend with the cities. Looking at Las Vegas and using Phoenix as a comparison. User choose to submit\n",
    "reviews about Restaurants, Nightlife and Bars whereas with a city like Phoenix while it still has these categorizes\n",
    "at the top, they do not draw the same percentage of the reviews that a city like Las Vegas does. The 'profile' that \n",
    "you could make about Las Vegas as it is very strong in the NightLife, Bars and Restaurants categories. Users that\n",
    "consistently review these categories would be drawn to this city more than others (like Phoenix) whos distribution\n",
    "of categories if more flatline vs.Las Vegas's heavy weight in those few categories. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. Different categories of ratings\n",
    "\n",
    "---\n",
    "\n",
    "Yelp is finally ready to admit that their rating system sucks. No one cares about the ratings, they just use the site to find out what's nearby. The ratings are simply too unreliable for people. \n",
    "\n",
    "Yelp hypothesizes that this is, in fact, because different people tend to give their ratings based on different things. They believe that perhaps some people always base their ratings on quality of food, others on service, and perhaps other categories as well. \n",
    "\n",
    "1. Do some users tend to talk about service more than others in reviews/tips? Divide up the tips/reviews into more \"service-focused\" ones and those less concerned with service.\n",
    "2. Create two new ratings for businesses: ratings from just the service-focused reviews and ratings from the non-service reviews.\n",
    "3. Construct a regression model for each of the two ratings. They should use the same predictor variables (of your choice). \n",
    "4. Validate the performance of the models.\n",
    "5. Do the models coefficients differ at all? What does this tell you about the hypothesis that there are in fact two different kinds of ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rev = pd.read_csv('/Users/austinwhaley/Desktop/DSI-SF-4-austinmwhaley/uber-pickups-in-new-york-city/bigquery-dsi-dave:yelp_arizona.reviews.csv')\n",
    "rev = rev.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>business_id</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>minutes_10</th>\n",
       "      <th>minutes_15</th>\n",
       "      <th>...</th>\n",
       "      <th>service_great</th>\n",
       "      <th>staff_friendly</th>\n",
       "      <th>super_friendly</th>\n",
       "      <th>sweet_potato</th>\n",
       "      <th>tasted_like</th>\n",
       "      <th>time_vegas</th>\n",
       "      <th>try_place</th>\n",
       "      <th>ve_seen</th>\n",
       "      <th>ve_tried</th>\n",
       "      <th>wait_staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69FrinUznWTIhi10KlzmMg</td>\n",
       "      <td>vBsA_oSgSB7i1-7PH1wNbw</td>\n",
       "      <td>0</td>\n",
       "      <td>bzDs0u8I-z231QVdIQWkrA</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cpD7H8kqPFRUE856HWMNAQ</td>\n",
       "      <td>qF-HfOUEOF1NGF9h9oNGuw</td>\n",
       "      <td>0</td>\n",
       "      <td>ERtc-EXdP9erEBoh7droww</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fGdiumEqJAMWIIChrTvjHA</td>\n",
       "      <td>UJ6_ZIS4poBtTbYN3qmm7w</td>\n",
       "      <td>0</td>\n",
       "      <td>Ov-brVmYdVfbupMoyjUU3A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-09-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fu35orOPJYTXyJ1LRs1VOA</td>\n",
       "      <td>kCy1P8KOZIt5VstuwAUl3A</td>\n",
       "      <td>0</td>\n",
       "      <td>NrvxRziDvF4HhfbY0RY1Lg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-07-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wp-zKEwZVIyKG0uc8iEJ9g</td>\n",
       "      <td>xiSjDTzaRqdYTtj60nDFog</td>\n",
       "      <td>0</td>\n",
       "      <td>TepgC3JV7NXjPPbKbzloiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id               review_id  votes_cool  \\\n",
       "0  69FrinUznWTIhi10KlzmMg  vBsA_oSgSB7i1-7PH1wNbw           0   \n",
       "1  cpD7H8kqPFRUE856HWMNAQ  qF-HfOUEOF1NGF9h9oNGuw           0   \n",
       "2  fGdiumEqJAMWIIChrTvjHA  UJ6_ZIS4poBtTbYN3qmm7w           0   \n",
       "3  Fu35orOPJYTXyJ1LRs1VOA  kCy1P8KOZIt5VstuwAUl3A           0   \n",
       "4  wp-zKEwZVIyKG0uc8iEJ9g  xiSjDTzaRqdYTtj60nDFog           0   \n",
       "\n",
       "              business_id  votes_funny  stars        date  votes_useful  \\\n",
       "0  bzDs0u8I-z231QVdIQWkrA            0      5  2014-12-12             0   \n",
       "1  ERtc-EXdP9erEBoh7droww            0      5  2013-05-28             0   \n",
       "2  Ov-brVmYdVfbupMoyjUU3A            0      5  2015-09-19             0   \n",
       "3  NrvxRziDvF4HhfbY0RY1Lg            0      5  2012-07-20             0   \n",
       "4  TepgC3JV7NXjPPbKbzloiQ            0      5  2010-02-06             0   \n",
       "\n",
       "   minutes_10  minutes_15     ...      service_great  staff_friendly  \\\n",
       "0           0           0     ...                  0               0   \n",
       "1           0           0     ...                  0               0   \n",
       "2           0           0     ...                  0               0   \n",
       "3           0           0     ...                  0               0   \n",
       "4           0           0     ...                  0               0   \n",
       "\n",
       "   super_friendly  sweet_potato  tasted_like  time_vegas  try_place  ve_seen  \\\n",
       "0               0             0            0           0          0        0   \n",
       "1               0             0            0           0          0        0   \n",
       "2               0             0            0           0          0        0   \n",
       "3               0             0            0           0          0        0   \n",
       "4               0             0            0           0          0        0   \n",
       "\n",
       "   ve_tried  wait_staff  \n",
       "0         0           0  \n",
       "1         0           0  \n",
       "2         0           0  \n",
       "3         0           0  \n",
       "4         0           0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "review_id\n",
      "votes_cool\n",
      "business_id\n",
      "votes_funny\n",
      "stars\n",
      "date\n",
      "votes_useful\n",
      "minutes_10\n",
      "minutes_15\n",
      "minutes_20\n",
      "minutes_30\n",
      "bar_food\n",
      "beer_selection\n",
      "best_ve\n",
      "bloody_mary\n",
      "bottle_service\n",
      "chicken_waffles\n",
      "customer_service\n",
      "dance_floor\n",
      "decided_try\n",
      "definitely_come\n",
      "definitely_recommend\n",
      "didn_want\n",
      "don_know\n",
      "don_like\n",
      "don_think\n",
      "don_want\n",
      "eggs_benedict\n",
      "fast_food\n",
      "feel_like\n",
      "felt_like\n",
      "fish_chips\n",
      "food_amazing\n",
      "food_came\n",
      "food_delicious\n",
      "food_good\n",
      "food_great\n",
      "food_just\n",
      "food_service\n",
      "french_fries\n",
      "french_toast\n",
      "friday_night\n",
      "fried_chicken\n",
      "friendly_staff\n",
      "good_food\n",
      "good_place\n",
      "good_service\n",
      "good_thing\n",
      "good_time\n",
      "great_atmosphere\n",
      "great_experience\n",
      "great_food\n",
      "great_place\n",
      "great_service\n",
      "great_time\n",
      "happy_hour\n",
      "hash_browns\n",
      "highly_recommend\n",
      "hip_hop\n",
      "ice_cream\n",
      "just_like\n",
      "just_ok\n",
      "just_right\n",
      "las_vegas\n",
      "late_night\n",
      "like_place\n",
      "little_bit\n",
      "long_time\n",
      "looked_like\n",
      "looks_like\n",
      "love_place\n",
      "mac_cheese\n",
      "make_sure\n",
      "mashed_potatoes\n",
      "medium_rare\n",
      "minutes_later\n",
      "new_york\n",
      "onion_rings\n",
      "place_good\n",
      "place_great\n",
      "place_just\n",
      "potato_fries\n",
      "pretty_good\n",
      "quality_food\n",
      "really_enjoyed\n",
      "really_good\n",
      "really_like\n",
      "really_nice\n",
      "recommend_place\n",
      "red_velvet\n",
      "right_away\n",
      "saturday_night\n",
      "second_time\n",
      "service_excellent\n",
      "service_food\n",
      "service_friendly\n",
      "service_good\n",
      "service_great\n",
      "staff_friendly\n",
      "super_friendly\n",
      "sweet_potato\n",
      "tasted_like\n",
      "time_vegas\n",
      "try_place\n",
      "ve_seen\n",
      "ve_tried\n",
      "wait_staff\n"
     ]
    }
   ],
   "source": [
    "for i in rev.columns:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rev['good_service'] = rev['good_service'].map(lambda x: x if x == 1 or x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    316391\n",
       "1      6007\n",
       "Name: good_service, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev['good_service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rev['review_type'] = rev['good_service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Service - Reviews/Tips\n",
    "-Take the Reviews/Tips category and divide them into more 'service-based' ones and those less concerned with service\n",
    "-Construct two new ratings for businesses: ratings from just the service-focused revews and ratings from the\n",
    "non-service reviews\n",
    "-Constuct a LR model for each of the two ratings. Use the same X data\n",
    "-Cross_Val_score them\n",
    "-Analysis the results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "What X data represents Reviews/Tips: Service & Non-Service\n",
    "Predict Service Label\n",
    "\n",
    "Create two new ratings: ratings from just the service-focused reviews and ratings from the non-service reviews\n",
    "(2 categories)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = rev[['good_service']]\n",
    "y = rev['review_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.] \n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "scores = cross_val_score(LR, X_test, y_test)\n",
    "print scores, '\\n'\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The meaning of this question is confusing to me as you want me to predict (with regression) which category\n",
    "(discrete value) that a review falls into, service-related / not service-related. These reviews would be directly\n",
    "based of categories that where set forth by me which is why it is a perfect model above. Also the values for the\n",
    "ratings where 0 or 1. That could mean that for example 0 the restaurant did not have good service or 0 that this \n",
    "review in question did not have to do with service at all. This applies to all variables in question. Therefore,\n",
    "how could a model be derived from the data?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 4. Identifying \"elite\" users\n",
    "\n",
    "---\n",
    "\n",
    "Yelp, though having their own formula for determining whether a user is elite or not, is interested in delving deeper into what differentiates an elite user from a normal user at a broader level.\n",
    "\n",
    "Use a classification model to predict whether a user is elite or not. Note that users can be elite in some years and not in others.\n",
    "\n",
    "1. What things predict well whether a user is elite or not?\n",
    "- Validate the model.\n",
    "- If you were to remove the \"counts\" metrics for users (reviews, votes, compliments), what distinguishes an elite user, if anything? Validate the model and compare it to the one with the count variables.\n",
    "- Think of a way to visually represent your results in a compelling way.\n",
    "- Give a brief write-up of your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Predict if user is elite or not\n",
    "use all valid columns\n",
    "MAKE AND VALIDATE MODEL\n",
    "With the same model, take away the reviews, votes and compliments-- same result?\n",
    "Write up findings\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'yelping_since', u'compliments_plain', u'review_count',\n",
       "       u'compliments_cute', u'compliments_writer', u'fans',\n",
       "       u'compliments_note', u'compliments_hot', u'compliments_cool',\n",
       "       u'compliments_profile', u'average_stars', u'compliments_more', u'elite',\n",
       "       u'name', u'user_id', u'votes_cool', u'compliments_list', u'votes_funny',\n",
       "       u'compliments_photos', u'compliments_funny', u'votes_useful'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>compliments_plain</th>\n",
       "      <th>review_count</th>\n",
       "      <th>compliments_cute</th>\n",
       "      <th>compliments_writer</th>\n",
       "      <th>fans</th>\n",
       "      <th>compliments_note</th>\n",
       "      <th>compliments_hot</th>\n",
       "      <th>compliments_cool</th>\n",
       "      <th>compliments_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>compliments_more</th>\n",
       "      <th>elite</th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>compliments_list</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>compliments_photos</th>\n",
       "      <th>compliments_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Scott</td>\n",
       "      <td>dMeSxE7S6Yxhz3cBgd6Sjw</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Diego</td>\n",
       "      <td>c-e0BxGy3eNtKzKDrrHyGw</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Katie</td>\n",
       "      <td>tO-IKvmHn9kGobTcVweTeA</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ross</td>\n",
       "      <td>soPELsow5JAqNSYCUmntJg</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Pam</td>\n",
       "      <td>RR6dZa6dkrcgjKvEnI-Myw</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  yelping_since  compliments_plain  review_count  compliments_cute  \\\n",
       "0       2015-01                NaN             1               NaN   \n",
       "1       2015-01                NaN             1               NaN   \n",
       "2       2015-01                NaN             2               NaN   \n",
       "3       2015-01                NaN             9               NaN   \n",
       "4       2015-01                NaN             2               NaN   \n",
       "\n",
       "   compliments_writer  fans  compliments_note  compliments_hot  \\\n",
       "0                 NaN     0               NaN              NaN   \n",
       "1                 NaN     0               NaN              NaN   \n",
       "2                 NaN     0               NaN              NaN   \n",
       "3                 NaN     0               NaN              NaN   \n",
       "4                 NaN     0               NaN              NaN   \n",
       "\n",
       "   compliments_cool  compliments_profile      ...       compliments_more  \\\n",
       "0               NaN                  NaN      ...                    NaN   \n",
       "1               NaN                  NaN      ...                    NaN   \n",
       "2               NaN                  NaN      ...                    NaN   \n",
       "3               NaN                  NaN      ...                    NaN   \n",
       "4               NaN                  NaN      ...                    NaN   \n",
       "\n",
       "   elite   name                 user_id votes_cool  compliments_list  \\\n",
       "0     []  Scott  dMeSxE7S6Yxhz3cBgd6Sjw          0              None   \n",
       "1     []  Diego  c-e0BxGy3eNtKzKDrrHyGw          0              None   \n",
       "2     []  Katie  tO-IKvmHn9kGobTcVweTeA          0              None   \n",
       "3     []   Ross  soPELsow5JAqNSYCUmntJg          2              None   \n",
       "4     []    Pam  RR6dZa6dkrcgjKvEnI-Myw          0              None   \n",
       "\n",
       "  votes_funny  compliments_photos compliments_funny  votes_useful  \n",
       "0           0                None               NaN             0  \n",
       "1           0                None               NaN             0  \n",
       "2           0                None               NaN             0  \n",
       "3           1                None               NaN             0  \n",
       "4           0                None               NaN             0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users['elite'] = users['elite'].map(lambda x: 0 if x == '[]' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    127583\n",
       "1     16623\n",
       "Name: elite, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['elite'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144206, 6)\n",
      "(47034, 6)\n"
     ]
    }
   ],
   "source": [
    "users = users[['review_count', 'votes_cool', 'compliments_plain', 'average_stars', 'fans', 'elite']]\n",
    "print users.shape\n",
    "users = users.dropna()\n",
    "print users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = users.drop('elite', 1)\n",
    "y = users['elite']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85204082  0.86709184  0.85965808] \n",
      "\n",
      "0.8595969097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train, y_train)\n",
    "scores = cross_val_score(KNN, X_test, y_test)\n",
    "print scores, '\\n'\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47034, 3)\n"
     ]
    }
   ],
   "source": [
    "users = users[['average_stars', 'fans', 'elite']]\n",
    "users = users.dropna()\n",
    "print users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = users.drop('elite', 1)\n",
    "y = users['elite']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82606478  0.82342434  0.83235519] \n",
      "\n",
      "0.82728143833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train, y_train)\n",
    "scores = cross_val_score(KNN, X_test, y_test)\n",
    "print scores, '\\n'\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "External factors such as the 'count' categories do little good in identifing 'ELITE' users as 'fans' and 'average stars\n",
    "where enough to get almost an identical match to the model that used 'count' columns. If wants wants to predict\n",
    "elite users (or potentially make more of them) they just need users to follow the behaviors of the set columns\n",
    "and that will lead to more elite users which is of course better for them. They also dont have to train their\n",
    "models on as much data if they only need a few predictors\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 5. Find something interesting on your own\n",
    "\n",
    "---\n",
    "\n",
    "You want to impress your superiors at Yelp by doing some investigation into the data on your own. You want to do classification, but you're not sure on what.\n",
    "\n",
    "1. Create a hypothesis or hypotheses about the data based on whatever you are interested in, as long as it is predicting a category of some kind (classification).\n",
    "2. Explore the data visually (ideally related to this hypothesis).\n",
    "3. Build one or more classification models to predict your target variable. **Your modeling should include gridsearching to find optimal model parameters.**\n",
    "4. Evaluate the performance of your model. Explain why your model may have chosen those specific parameters during the gridsearch process.\n",
    "5. Write up what the model tells you. Does it validate or invalidate your hypothesis? Write this up as if for a non-technical audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 6. ROC and Precision-recall\n",
    "\n",
    "---\n",
    "\n",
    "Some categories have fewer overall businesses than others. Choose two categories of businesses to predict, one that makes your proportion of target classes as even as possible, and another that has very few businesses and thus makes the target varible imbalanced.\n",
    "\n",
    "1. Create two classification models predicting these categories. Optimize the models and choose variables as you see fit.\n",
    "- Make confusion matrices for your models. Describe the confusion matrices and explain what they tell you about your models' performance.\n",
    "- Make ROC curves for both models. What do the ROC curves describe and what do they tell you about your model?\n",
    "- Make Precision-Recall curves for the models. What do they describe? How do they compare to the ROC curves?\n",
    "- Explain when Precision-Recall may be preferable to ROC. Is that the case in either of your models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
